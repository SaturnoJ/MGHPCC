{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Index\r\n",
    "1. Introduction\r\n",
    "2. Prequisites\r\n",
    "3. MSFragger + PeptideProphet\r\n",
    "4. ProteinProphet + Philosopher\r\n",
    "5. Write .quantindex\r\n",
    "6. IonQuant"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MSfragger + PeptideProphet\r\n",
    "\r\n",
    "![alt text](Images/fraggerpeptideprophet.png \"Title\")\r\n",
    "\r\n",
    "\r\n",
    "For each input file (.raw, .d, .xzml) the MSfragger and PeptideProphet processes will result in an .pepXML and .pep.xml file, respectively. The creation these files does not require any interaction between input samples, and thus could be parallelized. To do so, the user has to give the following information to the script:\r\n",
    "1. Location of the .d Bruker Files\r\n",
    "2. Location of the output directory\r\n",
    "3. Number of files per batch (we suggest to use a minimum of 20*)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "Based on the user input the XXXX.sh script will determine the number of .d files in the directory and start multiple batches based on the user input, with the last batch always including the modulo. For each batch it will run the Sbatch_MSfragger.sh script, which includes SLURM specifics, as well as loading and starting the singularity container. The container (Ubuntu XXX) will execute the following steps:\r\n",
    "1. Make directories (msfragger, timstoffiles, outputfiles).\r\n",
    "2. Copy msfragger from network to node.\r\n",
    "3. Copy .d files to node **\r\n",
    "4. Make sub-directories and set up the philosopher workspace for each .d file in the outputfiles directory\r\n",
    "5. Run the MSfragger java process\r\n",
    "6. Copy the .pepXML files from the timstoffiles directory to the outputfiles directory\r\n",
    "7. Run the PeptideProphet java process\r\n",
    "8. Copy outputfiles from Node to network storage\r\n",
    "9. Remove directories from the Node.\r\n",
    "\r\n",
    "\r\n",
    "*We noticed that if only a few bruker files are processed it might alter the fragment index width between batches. In our experience, batches of at least 20 will always lead to fragment indices of XX and XX, respectivly.\r\n",
    "\r\n",
    "**We noticed that if we do not copy the .d files to the node speed was vastly reduced. During the loading of the .d file (i.e. writing the .mzBIN file) we observed a high number of read/write processes. Having the .d files locally on the Node compared to over the network vastly improved the speed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "a5e9669fc23686289bab8faee75cf5c458b29840ff2a1c38e2ed113a10858e16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}